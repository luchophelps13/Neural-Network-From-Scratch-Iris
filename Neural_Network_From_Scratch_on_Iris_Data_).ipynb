{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network From Scratch on Iris Data :).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vp3-MTYAcBDJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()"
      ],
      "metadata": {
        "id": "_miA2IrdkzSC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"data\"]\n",
        "y = data[\"target\"]\n",
        "fn = data[\"feature_names\"]"
      ],
      "metadata": {
        "id": "datYPPCkk9xE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}"
      ],
      "metadata": {
        "id": "qUMSkwMHmAmV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y)):\n",
        "  print(tn[y[i]])"
      ],
      "metadata": {
        "id": "k7QsmXJalRWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X[0:120]#.reshape(4, -1)\n",
        "X_test = X[120:]#.reshape(4, -1)\n",
        "y_train = y[0:120]#.reshape(-1, 1)\n",
        "y_test = y[120:]#.reshape(-1, 1)\n",
        "#\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXwSbdI-0OIG",
        "outputId": "3d914fc3-5639-454c-98f2-a384eb39d21b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4) (30, 4) (120,) (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "  def __init__(self, learning_rate, epochs):\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.m = y.size\n",
        "\n",
        "  def init_params(self):\n",
        "    W1 = np.random.randn(4, 10) \n",
        "    B1 = np.random.randn(120, 1) \n",
        "\n",
        "    W2 = np.random.randn(10, 3) \n",
        "    B2 = np.random.randn(120, 1)    \n",
        "\n",
        "    return W1, B1, W2, B2\n",
        "\n",
        "  def forward_prop(self, X, W1, B1, W2, B2):\n",
        "\n",
        "    Z1 = X.dot(W1) + B1 \n",
        "    A1 = self._ReLu(Z1) \n",
        "\n",
        "    Z2 = A1.dot(W2) + B2 \n",
        "    A2 = self._SoftMax(Z2)\n",
        "\n",
        "    return A1, Z1, A2, Z2\n",
        "\n",
        "  def back_prop(self, X, y, W1, W2, A1, A2, Z1, Z2):\n",
        "     \n",
        "    # Calculate derivatives\n",
        "\n",
        "    ohy = self._OneHotEncode(y)\n",
        "\n",
        "\n",
        "    d_Z2 = (A2 - ohy).T\n",
        "\n",
        "    d_W2 = 1/self.m * d_Z2.dot(A1)\n",
        "\n",
        "    d_B2 = 1/self.m * np.sum(d_Z2)\n",
        "\n",
        "\n",
        "    d_Z1 = W2.dot(d_Z2) * self._DReLu(Z1).T\n",
        "\n",
        "\n",
        "    d_W1 = 1/self.m * d_Z1.dot(X) \n",
        "\n",
        "    d_B1 = 1/self.m * np.sum(d_Z1)\n",
        "\n",
        "    return d_W1, d_B1, d_W2, d_B2\n",
        "\n",
        "\n",
        "  def update_params(self, lr, W1, W2, B1, B2, dW1, dW2, dB1, dB2):\n",
        "\n",
        "    W1 = W1 - (lr * dW1).T\n",
        "    B1 = B1 - (lr * dB1).T\n",
        "    W2 = W2 - (lr * dW2).T\n",
        "    B2 = B2 - (lr * dB2).T\n",
        "\n",
        "    return W1, B1, W2, B2\n",
        "\n",
        "  def _ReLu(self, z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "  def _DReLu(self, z):\n",
        "    return z > 0\n",
        "\n",
        "  def _SoftMax(self, z):\n",
        "    return np.exp(z) / np.sum(np.exp(z))\n",
        "\n",
        "  def _OneHotEncode(self, Y):\n",
        "\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    return one_hot_Y\n",
        "\n",
        "  def make_prediction(self, x_new, W1, b1, W2, b2):\n",
        "\n",
        "    final = self.forward_prop(x_new, W1, b1, W2, b2)[-1]\n",
        "\n",
        "    return final\n",
        "\n",
        "  def get_predictions(self, F):\n",
        "    g = np.zeros((F.shape[0], 1))\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    for row in F:\n",
        "      g[i] = np.argmax(row)\n",
        "      i += 1\n",
        "\n",
        "    return g.reshape(120)\n",
        "\n",
        "  def get_accuracy(self, predictions, Y):\n",
        "    accuracy = np.sum(predictions == Y) / Y.size\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "  def gradient_descent(self, X, y):\n",
        "    W1, b1, W2, b2 = self.init_params()\n",
        "    for i in range(self.epochs):\n",
        "        Z1, A1, Z2, A2 = self.forward_prop(X, W1, b1, W2, b2)\n",
        "        dW1, db1, dW2, db2 = self.back_prop(X, y, W1, W2, A1, A2, Z1, Z2)\n",
        "        W1, b1, W2, b2 = self.update_params(self.lr, W1, W2, b1, b2, dW1, dW2, db2, db2)\n",
        "        if i % 500 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = self.get_predictions(A2)\n",
        "            print(\"Accuracy: \", self.get_accuracy(predictions, y))\n",
        "    \n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "NN = NeuralNetwork(0.001, 10000)\n",
        "W1, b1, W2, b2 = NN.gradient_descent(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSuglLENmxzt",
        "outputId": "45ffda6f-a604-43b4-c39c-8e648e316f42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "Accuracy:  0.26666666666666666\n",
            "Iteration:  500\n",
            "Accuracy:  0.5916666666666667\n",
            "Iteration:  1000\n",
            "Accuracy:  0.6833333333333333\n",
            "Iteration:  1500\n",
            "Accuracy:  0.75\n",
            "Iteration:  2000\n",
            "Accuracy:  0.7583333333333333\n",
            "Iteration:  2500\n",
            "Accuracy:  0.8083333333333333\n",
            "Iteration:  3000\n",
            "Accuracy:  0.825\n",
            "Iteration:  3500\n",
            "Accuracy:  0.8333333333333334\n",
            "Iteration:  4000\n",
            "Accuracy:  0.85\n",
            "Iteration:  4500\n",
            "Accuracy:  0.875\n",
            "Iteration:  5000\n",
            "Accuracy:  0.875\n",
            "Iteration:  5500\n",
            "Accuracy:  0.875\n",
            "Iteration:  6000\n",
            "Accuracy:  0.875\n",
            "Iteration:  6500\n",
            "Accuracy:  0.875\n",
            "Iteration:  7000\n",
            "Accuracy:  0.875\n",
            "Iteration:  7500\n",
            "Accuracy:  0.875\n",
            "Iteration:  8000\n",
            "Accuracy:  0.8583333333333333\n",
            "Iteration:  8500\n",
            "Accuracy:  0.8666666666666667\n",
            "Iteration:  9000\n",
            "Accuracy:  0.8583333333333333\n",
            "Iteration:  9500\n",
            "Accuracy:  0.8583333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], tn[y_train[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-a65wZDFHI9",
        "outputId": "123a1fc6-b98d-49df-9525-8e100cccdf18"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5.1, 3.5, 1.4, 0.2]), 'setosa')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = np.array([5.0, 3.6, 1.3, 0.23])"
      ],
      "metadata": {
        "id": "5UyLwWgHE9Ai"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = NN.make_prediction(x_new, W1, b1, W2, b2)"
      ],
      "metadata": {
        "id": "PrJemlxbFKWo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn[NN.get_predictions(y_pred)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9EyqjC7sZgim",
        "outputId": "f877f02d-86ec-4ef4-d530-61670818bfe1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'setosa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}